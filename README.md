## Architect Big Data Solutions with Apache Spark

<img src="https://www.computing.co.uk/w-images/cc6f36ae-ffb1-4271-8847-725556046f5c/0/apachesparklogo-580x358.png" width="300" height="200" />

### Introduction 

This repository contains lectures and codes for the course that aims to provide 
a gentle introduction on how to build distributed big data pipelines with the help of Apache Spark. Furthermore, we try to address different capabilities of Apache Spark for building ETL/ Batch, Streaming, and Machine Learning data pipelines.

### Content

1. Introduction [[lecture 1]](Modules/01%20Introduction/Lectures/Lecture%201%20-%20Introduction%20to%20the%20Course.pdf) [[labs]](Modules/01%20Introduction/Labs) 
2. SQL and DataFrame [[labs]](Modules/02%20SQL%20and%20DataFrame)
3. Batch Processing [[lecture 2]](Modules/03%20Batch%20Processing/Lecture%202%20-%20Building%20Batch%20Applications.pdf) [[lecture 3]](Modules/03%20Batch%20Processing/Lecture%203%20-%20Our%20ETL%20Application.pdf)
4. Stream Processing [[lecture 4]](Modules/04%20Stream%20Processing/lectures/Lecture%204%20-%20Streaming%20Application.pdf) [[lecture 5]](Modules/04%20Stream%20Processing/lectures/Lecture%205%20-%20Spark%20Streaming%20vs%20Structured%20Streaming.pdf) [[labs]](Modules/04%20Stream%20Processing/Labs)
5. Machine Learning [[lecture 6]](Modules/05%20Machine%20Learning/Machine%20Learning%20In%20Spark%2C%20AWS%20and%20Kaggle.pdf) [[labs]](Modules/05%20Machine%20Learning/Lab)

### Computational Resources

1. Please register for **community** version of DataBricks [here](https://databricks.com/try-databricks).
2. Please register for free tier AWS account [here](https://aws.amazon.com/free/)

### Data Sources

You can find data and additional information from the links below:
1. [MovieLens DataSet](https://grouplens.org/datasets/movielens/)
2. [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
3. [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)

Note:  For you convenience data already downloaded to Datasets folder of this repository.

Note: You can upload data to DataBricks directly or use AWS S3 bucket for storage:
- [How to upload data to DataBricks](https://docs.databricks.com/user-guide/tables.html#create-table-ui)
- [Read CSV files from uploaded data](https://docs.databricks.com/spark/latest/data-sources/read-csv.html) 


### Additional Resources

We provide links for nice cheat sheets and books in order to make course as smooth as possible:

1. [A Gentle Introduction to Apache Spark](Resources/A_Gentle_Introduction_to_Apache_Spark.pdf)
2. [How to import Data to DataBricks using S3](Resources/Import_Data_to_Databricks.pdf)
3. [PySpark Cheat Sheet for Python](Resources/PySpark_Cheat_Sheet_for_Python.pdf)
4. [Python Cheat Sheet](Resources/Python_Cheat_Sheet.pdf)
5. [Machine Learning Tutorial for AWS](https://docs.aws.amazon.com/machine-learning/latest/dg/tutorial.html?icmpid=docs_machinelearning_console)
6. [DataBricks Development Documentation](https://docs.databricks.com/index.html)
7. [Developers Guide for AWS Machine Learning](https://docs.aws.amazon.com/machine-learning/latest/dg/what-is-amazon-machine-learning.html)
8. [Superset](https://superset.incubator.apache.org/)

### Course Initiative: 

* [Ekhtiar Syed](https://www.linkedin.com/in/ekhtiar/)
* [Vladimir Osin](https://www.linkedin.com/in/vosin/) 

If you like the initiative please star/fork that repository and feel free to contribute with pull requests.

### Places where this course has been taught (physically) 

* [Philips Lighting / Signify](https://www.signify.com)
* [Joint Master Data Science & Entrepreneurship@ JADS](https://www.jads.nl/joint-master-program-data-science-entrepreneurship.html)
* [Data Expert Program for Professionals @ JADS](https://www.jads.nl/dataexpertprogram.html) 
