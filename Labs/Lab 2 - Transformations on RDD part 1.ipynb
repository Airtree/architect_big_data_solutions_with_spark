{"cells":[{"cell_type":"code","source":["from pyspark import SparkContext, SparkConf"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["if not 'sc' in globals(): # This 'trick' makes sure the SparkContext sc is initialized exactly once\n    conf = SparkConf().setMaster('local[*]')\n    sc = SparkContext(conf=conf)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Replace with your values\n# NOTE: Set the access to this notebook appropriately to protect the security of your keys.\n# Or you can delete this cell after you run the mount command below once successfully.\nACCESS_KEY = \"none\"\nSECRET_KEY = \"none\"\nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"none\"\nMOUNT_NAME = \"none\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# only execute this line once\ntry: \n  dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\nexcept:\n  pass"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# For now we will just read data from a text file\ninput_rdd = sc.textFile(\"/mnt/%s/flights.csv\" % MOUNT_NAME)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Transformations\nTransformations are operations that will not be completed at the time you write and execute the code in a cell - they will only get executed once you have called an action. An example of a transformation might be to convert an integer into a float or to filter a set of values. In this section we will discuss the basic transformations that can be applied on top of RDD.\n##### map\nThe map method is a higher-order method that takes a function as input and applies it to each element in\nthe source RDD to create a new RDD. The input function to map must take a single input parameter and\nreturn a value."],"metadata":{}},{"cell_type":"code","source":["# just to show you the first line of the RDD\ninput_rdd.first()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# using the map function, I transformed my original RDD\ninput_list = input_rdd.map(lambda line: line.split(','))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# They are a list object now, instead of pure string\n# First is an action. ONLY AT THIS POINT SPARK WILL START PROCESSING\ninput_list.first()[:10]"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["##### filter\nThe filter method is a higher-order method that takes a Boolean function as input and applies it to each\nelement in the source RDD to create a new RDD. A Boolean function takes an input and returns true or\nfalse. The filter method returns a new RDD formed by selecting only those elements for which the input\nBoolean function returned true. Thus, the new RDD contains a subset of the elements in the original RDD."],"metadata":{}},{"cell_type":"code","source":["# the original input RDD has header\ninput_rdd.take(4)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# for processing the data I can get rid of the header with a filter operation\nflight_delay_rdd = input_rdd.filter(lambda line: 'YEAR' not in line)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# we got rid of the header\n# again, only at this point spark processes the data\nflight_delay_rdd.first()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["##### flatMap\nThe flatMap method is a higher-order method that takes an input function, which returns a sequence for\neach input element passed to it. The flatMap method returns a new RDD formed by flattening this collection\nof sequence."],"metadata":{}},{"cell_type":"code","source":["# imagine we want to know the total delay and we don't have ARRIVAL_DELAY and DEPARTURE_DELAY\n# so we must find out using the following fields\ninput_list.first()[26:]"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# split string input to a list object in python and then subset to the delays\ndifferent_delays_rdd = flight_delay_rdd.map(lambda line: line.split(',')).map(lambda line: line[26:])"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# Now we only have different delays in minutes\ndifferent_delays_rdd.first()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# If we want to replace the empty items on the list with 0 we can use the map function\ndifferent_delays_rdd.map(lambda delays: [delay if len(delay)>0 else 0 for delay in delays]).first()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# there are same number of lines as input (minus one for header)\ndifferent_delays_rdd.count()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# using flatMap we can represent each delay per line as a single object within our RDD\ndifferent_delay_rdd = different_delays_rdd.flatMap(lambda line: line)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# let's see how many lines we have now within our RDD|\ndifferent_delay_rdd.count()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["# our RDD became 5 time it's original size\n5819079 * 5"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# instead of 5 empty objects, we have one empty object for our first line, makes sense? \ndifferent_delay_rdd.filter(lambda line: line!='').take(10)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["##### Writing Custom Functions\nYou can write custom functions to process each line within RDD, as illustrated below"],"metadata":{}},{"cell_type":"code","source":["# if our line is empty this function will return 0\n# otherwise it will convert it to an integer\ndef convert_to_int(line):\n    try:\n        return int(line)\n    except:\n        return 0"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["different_delay_int_rdd = different_delay_rdd.map(convert_to_int)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["different_delay_int_rdd = different_delay_rdd.map(convert_to_int)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# print out a non-zero delay from our RDD\ndifferent_delay_int_rdd.filter(lambda line: line is not 0).first()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# now if you wanted to know the total flight delays (hours) that happened in USA in the year 2015 you can use sum() which is an action\ndifferent_delay_int_rdd.sum() / 60.0"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["##### union\nThe union method takes an RDD as input and returns a new RDD that contains the union of the elements in the source RDD and the RDD passed to it as an input.\n\n```linesFile1 = sc.textFile(\"...\")\nlinesFile2 = sc.textFile(\"...\")\nlinesFromBothFiles = linesFile1.union(linesFile2)```"],"metadata":{}},{"cell_type":"code","source":["mammals = sc.parallelize([\"Lion\", \"Dolphin\", \"Whale\"])\naquatics = sc.parallelize([\"Shark\", \"Dolphin\", \"Whale\"])\nzoo = mammals.union(aquatics)\nzoo.collect()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["##### intersection\nThe intersection method takes an RDD as input and returns a new RDD that contains the intersection of\nthe elements in the source RDD and the RDD passed to it as an input.\n\n```val linesFile1 = sc.textFile(\"...\")\nval linesFile2 = sc.textFile(\"...\")\nval linesPresentInBothFiles = linesFile1.intersection(linesFile2)```"],"metadata":{}},{"cell_type":"code","source":["mammals = sc.parallelize([\"Lion\", \"Dolphin\", \"Whale\"])\naquatics = sc.parallelize([\"Shark\", \"Dolphin\", \"Whale\"])\naquaticMammals = mammals.intersection(aquatics)\naquaticMammals.collect()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["##### subtract\nThe subtract method takes an RDD as input and returns a new RDD that contains elements in the source\nRDD but not in the input RDD.\n```linesFile1 = sc.textFile(\"...\")\nlinesFile2 = sc.textFile(\"...\")\nlinesInFile1Only = linesFile1.subtract(linesFile2)```"],"metadata":{}},{"cell_type":"code","source":["mammals = sc.parallelize([\"Lion\", \"Dolphin\", \"Whale\"])\naquatics =sc.parallelize([\"Shark\", \"Dolphin\", \"Whale\"])\nfishes = aquatics.subtract(mammals)\nfishes.collect()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["##### distinct\nThe distinct method of an RDD returns a new RDD containing the distinct elements in the source RDD"],"metadata":{}},{"cell_type":"code","source":["# Airline is in the fourth index on our RDD list\ninput_list.map(lambda line: line[4]).first()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["airlines_rdd = flight_delay_rdd.map(lambda line: line.split(',')[4])"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# these are two letter airline code\nairlines_rdd.first()"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["# how many different airlines do we have in our dataset\nairlines_rdd.distinct().count()"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["# show all the distinct airlines in our dataset\nairlines_rdd.distinct().collect()"],"metadata":{},"outputs":[],"execution_count":41}],"metadata":{"name":"Spark Lab 2 Public","notebookId":1304373198374469},"nbformat":4,"nbformat_minor":0}
